{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Comedy Sketch Creation System with Moya\n",
    "\n",
    "This notebook demonstrates how to create a multi-agent comedy sketch creation system using Moya for the multi-agent framework with OpenAI agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, let's install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CHROMADB_CLIENT\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moya.agents.openai_agent import OpenAIAgent, OpenAIAgentConfig\n",
    "from moya.agents.remote_agent import RemoteAgent, RemoteAgentConfig\n",
    "from moya.classifiers.llm_classifier import LLMClassifier\n",
    "from moya.orchestrators.multi_agent_orchestrator import MultiAgentOrchestrator\n",
    "from moya.registry.agent_registry import AgentRegistry\n",
    "from moya.tools.ephemeral_memory import EphemeralMemory\n",
    "from moya.memory.in_memory_repository import InMemoryRepository\n",
    "from moya.tools.tool_registry import ToolRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI API configuration loaded from .env file\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get Azure OpenAI credentials\n",
    "azure_api_key = os.environ.get(\"AZURE_azure_api_key\")\n",
    "azure_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "# Define Azure deployment name - you'll need to replace this with your actual deployment name\n",
    "deployment_name = \"gpt-4o\"  # Replace with your Azure deployment name\n",
    "\n",
    "# Create an Azure OpenAI client\n",
    "azure_client = AzureOpenAI(\n",
    "    api_key=azure_api_key,\n",
    "    api_version=azure_api_version,\n",
    "    azure_endpoint=azure_endpoint\n",
    ")\n",
    "\n",
    "# Verify the environment variables are loaded\n",
    "print(\"Azure OpenAI API configuration loaded from .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent Registry and Tool Registry\n",
    "\n",
    "Setting up the foundation for our multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tool registry to manage tools that agents can use\n",
    "tool_registry = ToolRegistry()\n",
    "\n",
    "# Add EphemeralMemory tool to allow agents to remember information\n",
    "EphemeralMemory.configure_memory_tools(tool_registry)\n",
    "\n",
    "# Create an agent registry to manage our agents\n",
    "agent_registry = AgentRegistry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define OpenAI Agents\n",
    "\n",
    "We'll create five comedy sketch creation agents with different roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up API key - replace with your actual OpenAI API key\n",
    "azure_api_key = os.getenv(\"azure_api_key\", \"your-api-key-here\")\n",
    "\n",
    "# Create a Premise & Concept Generator agent\n",
    "concept_generator_config = OpenAIAgentConfig(\n",
    "    agent_name=\"concept_generator\",\n",
    "    agent_type=\"openai\",\n",
    "    description=\"Proposes unique comedic premises, absurd scenarios, and humorous character ideas based on themes or genres.\",\n",
    "    system_prompt=\"\"\"You are an expert comedy concept generator. Your specialty is creating fresh, \n",
    "    engaging comedy sketch premises that align with user preferences. You excel at developing \n",
    "    absurd scenarios, unique character concepts, and innovative comedic situations. Focus on \n",
    "    originality while ensuring the concepts have strong comedic potential.\"\"\",\n",
    "    model_name=\"gpt-4o\",  # You can change this to your preferred model\n",
    "    api_key=azure_api_key,\n",
    "    tool_registry=tool_registry\n",
    ")\n",
    "concept_generator = OpenAIAgent(concept_generator_config)\n",
    "concept_generator.client = azure_client\n",
    "\n",
    "# Create a Dialogue & Punchline Refinement agent\n",
    "dialogue_refiner_config = OpenAIAgentConfig(\n",
    "    agent_name=\"dialogue_refiner\",\n",
    "    agent_type=\"openai\",\n",
    "    description=\"Suggests witty dialogue, one-liners, and comedic callbacks while ensuring proper setup and delivery.\",\n",
    "    system_prompt=\"\"\"You are a skilled comedy dialogue writer who excels at crafting witty dialogue, \n",
    "    memorable one-liners, and effective comedic callbacks. Your expertise is in enhancing timing, \n",
    "    phrasing, and impact to make sketches entertaining and memorable. Ensure proper setup and delivery \n",
    "    for maximum comedic effect.\"\"\",\n",
    "    model_name=\"gpt-4o\",  # You can change this to your preferred model\n",
    "    api_key=azure_api_key,\n",
    "    tool_registry=tool_registry\n",
    ")\n",
    "dialogue_refiner = OpenAIAgent(dialogue_refiner_config)\n",
    "dialogue_refiner.client = azure_client\n",
    "\n",
    "# Create a Sketch Structure & Timing agent\n",
    "structure_timing_config = OpenAIAgentConfig(\n",
    "    agent_name=\"structure_timing\",\n",
    "    agent_type=\"openai\",\n",
    "    description=\"Organizes comedic escalation, beats, and timing cues to create well-paced sketches.\",\n",
    "    system_prompt=\"\"\"You are an expert in comedy sketch structure and timing. You excel at organizing \n",
    "    comedic escalation, beats, and timing cues to create well-paced sketches. Your role is to ensure \n",
    "    that sketches flow naturally and land effectively, avoiding pacing issues and maximizing comedic impact. \n",
    "    Provide clear guidance on sketch structure, including intros, escalation points, and satisfying endings.\"\"\",\n",
    "    model_name=\"gpt-4o\",  # You can change this to your preferred model\n",
    "    api_key=azure_api_key,\n",
    "    tool_registry=tool_registry\n",
    ")\n",
    "structure_timing = OpenAIAgent(structure_timing_config)\n",
    "structure_timing.client = azure_client\n",
    "\n",
    "# Create an Audience Adaptation & Cultural Context agent\n",
    "audience_adaptation_config = OpenAIAgentConfig(\n",
    "    agent_name=\"audience_adaptation\",\n",
    "    agent_type=\"openai\",\n",
    "    description=\"Adjusts tone, references, and comedic elements to suit different audiences, platforms, or performance styles.\",\n",
    "    system_prompt=\"\"\"You are a specialist in tailoring comedy for specific audiences. Your expertise is \n",
    "    in adjusting tone, references, and comedic elements to suit different audiences, platforms, or \n",
    "    performance styles. You make material relatable and impactful for specific demographics or regions \n",
    "    while maintaining the core comedic elements of the sketch.\"\"\",\n",
    "    model_name=\"gpt-4o\",  # You can change this to your preferred model\n",
    "    api_key=azure_api_key,\n",
    "    tool_registry=tool_registry\n",
    ")\n",
    "audience_adaptation = OpenAIAgent(audience_adaptation_config)\n",
    "audience_adaptation.client = azure_client\n",
    "\n",
    "# Create a Collaborative Brainstorming & Variation agent\n",
    "variation_agent_config = OpenAIAgentConfig(\n",
    "    agent_name=\"variation_agent\",\n",
    "    agent_type=\"openai\",\n",
    "    description=\"Provides alternate takes, subversions of tropes, and unexpected comedic twists to avoid predictable humor.\",\n",
    "    system_prompt=\"\"\"You are a creative comedy brainstormer who specializes in providing alternate takes, \n",
    "    subversions of tropes, and unexpected comedic twists. Your goal is to help avoid predictable humor \n",
    "    by encouraging creativity, spontaneity, and uniqueness in sketch writing. Offer multiple variations \n",
    "    and surprising directions to take comedy sketches.\"\"\",\n",
    "    model_name=\"gpt-4o\",  # You can change this to your preferred model\n",
    "    api_key=azure_api_key,\n",
    "    tool_registry=tool_registry\n",
    ")\n",
    "variation_agent = OpenAIAgent(variation_agent_config)\n",
    "variation_agent.client = azure_client\n",
    "\n",
    "# Register all agents with the agent registry\n",
    "agent_registry.register_agent(concept_generator)\n",
    "agent_registry.register_agent(dialogue_refiner)\n",
    "agent_registry.register_agent(structure_timing)\n",
    "agent_registry.register_agent(audience_adaptation)\n",
    "agent_registry.register_agent(variation_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Classifier\n",
    "\n",
    "We need a classifier to route messages to the appropriate agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:\n",
    "# class LLMClassifier(BaseClassifier):\n",
    "#     \"\"\"LLM-based classifier for agent selection.\"\"\"\n",
    "\n",
    "#     def __init__(self, llm_agent: Agent, default_agent: str):\n",
    "#         \"\"\"\n",
    "#         Initialize with an LLM agent for classification.\n",
    "        \n",
    "#         :param llm_agent: An agent that will be used for classification\n",
    "#         :param default_agent: The default agent to use if no specialized match is found\n",
    "#         \"\"\"\n",
    "#         self.llm_agent = llm_agent\n",
    "#         self.default_agent = default_agent\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a classifier agent for routing messages\n",
    "classifier_agent_config = OpenAIAgentConfig(\n",
    "    agent_name=\"classifier\",\n",
    "    agent_type=\"openai\",\n",
    "    description=\"Routes messages to the appropriate specialized agent\",\n",
    "    system_prompt=\"You are a classifier that determines which specialized agent should handle a given request.\",\n",
    "    model_name=\"gpt-4o\",\n",
    "    api_key=azure_api_key,\n",
    "    tool_registry=tool_registry\n",
    ")\n",
    "classifier_agent = OpenAIAgent(classifier_agent_config)\n",
    "classifier_agent.client = azure_client\n",
    "\n",
    "# Create an LLM-based classifier to route messages to appropriate agents\n",
    "classifier = LLMClassifier(\n",
    "    llm_agent=classifier_agent,\n",
    "    default_agent=\"concept_generator\"  # Using concept_generator as default agent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Multi-Agent Orchestrator\n",
    "\n",
    "Now we'll create a multi-agent orchestrator to manage the interactions between agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi-agent orchestrator to manage interactions\n",
    "orchestrator = MultiAgentOrchestrator(\n",
    "    agent_registry=agent_registry,\n",
    "    classifier=classifier\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Multi-Agent Workflow\n",
    "\n",
    "Let's create a workflow for our comedy sketch creation project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored initial user request in memory\n"
     ]
    }
   ],
   "source": [
    "# Create the initial user request\n",
    "user_request = \"I need a comedy sketch about technology addiction in modern society, suitable for a YouTube audience.\"\n",
    "\n",
    "# Create a thread ID for this conversation\n",
    "thread_id = \"comedy_sketch_001\"\n",
    "\n",
    "# Store user request in memory properly using EphemeralMemory directly\n",
    "EphemeralMemory.store_message(thread_id=thread_id, sender=\"user\", content=user_request)\n",
    "print(f\"Stored initial user request in memory\")\n",
    "\n",
    "# Define the concept generation task\n",
    "concept_task = \"\"\"Generate 3 unique comedy sketch concepts about technology addiction in modern society. \n",
    "Each concept should include a brief premise, key characters, and the central comedic tension. \n",
    "Make the concepts fresh, engaging, and suitable for a YouTube audience.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation summary:\n",
      "Summary of thread comedy_sketch_001:\n",
      "user said: I need a comedy sketch about technology addiction in modern society, suitable for a YouTube audience.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get conversation summary from memory\n",
    "summary_tool = tool_registry.get_tool(\"get_summary\")\n",
    "if summary_tool:\n",
    "    summary = summary_tool.function(thread_id=thread_id)\n",
    "    print(f\"Conversation summary:\\n{summary}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Problem Solving\n",
    "\n",
    "Let's also demonstrate how the agents can work together to solve a comedy challenge interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored initial challenge in memory\n",
      "\n",
      "Collaborative Session - Concept Generator's Turn\n",
      "\n",
      "Concept Generator: [concept_generator] ### Sketch Title: \"Insta-Reality\"\n",
      "\n",
      "#### Characters:\n",
      "1. **Influencer Ida** - A social media influencer with an exaggerated online persona.\n",
      "2. **Follower Fran** - Ida's devoted follower who tries to imitate her every move.\n",
      "3. **Reality Ralph** - Ida's partner who is exhausted by her constant need for social media validation.\n",
      "4. **Narrator** - Occasionally steps in to provide humorous commentary.\n",
      "\n",
      "#### Setting:\n",
      "The stage is divided into two sections: one side represents Ida's filtered Instagram world (where everything looks perfect), and the other side represents her messy real life.\n",
      "\n",
      "---\n",
      "\n",
      "#### Scene 1: Introducing Influencer Ida\n",
      "\n",
      "*(Lights up on a glamorous set representing Instagram)*\n",
      "\n",
      "**Narrator:** (starts with a dramatic tone) Welcome to the fabulous world of Influencer Ida, where every moment is a picture-perfect paradise!\n",
      "\n",
      "*(Ida enters, posing exaggeratedly with a perfect smile while holding a giant fake phone.)*\n",
      "\n",
      "**Ida:** (speaking into the phone) Hey, Insta-fam! Just having a casual breakfast at my chic, cozy cafe! #blessed #goals\n",
      "\n",
      "*(Ralph appears from the real-life side, wearing pajamas and holding a messy plate of food.)*\n",
      "\n",
      "**Reality Ralph:** (grumbling) Ida, our kitchen looks like a tornado hit it, and we’re out of milk!\n",
      "\n",
      "*(Ida ignores Ralph and continues posing.)*\n",
      "\n",
      "#### Scene 2: The Imitation Game\n",
      "\n",
      "*(Follower Fran appears on the Instagram side, trying to imitate Ida's pose and struggling comically.)*\n",
      "\n",
      "**Follower Fran:** (with an over-the-top fake smile) Just having the best time ever, just like Ida! #livingmybestlife\n",
      "\n",
      "*(Fran's attempts become more absurd, leading to physical comedy—Fran falls off her chair, spills coffee, etc.)*\n",
      "\n",
      "**Narrator:** (sarcastically) Ah, the glamorous life of an influencer—and her faithful followers striving to keep up! \n",
      "\n",
      "#### Scene 3: The Candid Moment\n",
      "\n",
      "*(Ida sets up a camera on a tripod in real life and tries to film a \"candid\" morning routine but things keep going wrong.)*\n",
      "\n",
      "**Ida:** (fake cheerfully) Good morning, everyone! Just waking up to a beautiful day!\n",
      "\n",
      "*(Ralph accidentally spills the messy breakfast on Ida.)*\n",
      "\n",
      "**Reality Ralph:** (deadpan) Candid enough for ya?\n",
      "\n",
      "*(Audience sees the stark contrast between the messy reality and the perfect Instagram version on the split stage.)*\n",
      "\n",
      "#### Scene 4: The Social Media Blackout\n",
      "\n",
      "**Narrator:** But what happens when the social media world comes crashing down?\n",
      "\n",
      "*(Lights flicker on the Instagram side, simulating a blackout. Ida panics.)*\n",
      "\n",
      "**Ida:** No WiFi!? No Instagram!? What will my followers think!?\n",
      "\n",
      "*(Fran enters frantically but trips and falls over objects in the real-life side, leading to more physical comedy.)*\n",
      "\n",
      "#### Scene 5: Real-Life Revelation\n",
      "\n",
      "**Reality Ralph:** (calmly) Maybe it’s time we live in the moment, Ida. Look around you—the real world needs you too.\n",
      "\n",
      "*(Ida starts to see the mess around her and the absurdity of the situation. She decides to embrace reality.)*\n",
      "\n",
      "**Ida:** (realization dawning) Maybe you're right, Ralph. (looking at the audience) Sometimes, reality beats any filter.\n",
      "\n",
      "*(Fran stands up, disheveled but with a genuine smile, and joins Ida and Ralph in a group hug.)*\n",
      "\n",
      "**Narrator:** And so, our story reminds us that while social media might paint a pretty picture, the true beauty lies in our unfiltered lives.\n",
      "\n",
      "*(Curtain falls as the audience cheers and claps.)*\n",
      "\n",
      "---\n",
      "\n",
      "### End of Sketch\n",
      "\n",
      "This sketch leverages physical comedy, such as Fran's exaggerated imitation mishaps and Ralph's casual realism clashing with Ida's hyper-perfection, to provide a humorous yet poignant commentary on social media influence and the importance of embracing reality.\n",
      "\n",
      "Collaborative Session - Dialogue Refiner's Turn\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m summary_tool:\n\u001b[32m     29\u001b[39m     summary = summary_tool.function(thread_id=collab_thread_id)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m dialogue_contribution = \u001b[43morchestrator\u001b[49m\u001b[43m.\u001b[49m\u001b[43morchestrate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollab_thread_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_message\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdialogue_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mPrevious contributions: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdialogue_refiner\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     35\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m EphemeralMemory.store_message(thread_id=collab_thread_id, sender=\u001b[33m\"\u001b[39m\u001b[33mdialogue_refiner\u001b[39m\u001b[33m\"\u001b[39m, content=dialogue_contribution)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDialogue Refiner: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdialogue_contribution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/moya/orchestrators/multi_agent_orchestrator.py:82\u001b[39m, in \u001b[36mMultiAgentOrchestrator.orchestrate\u001b[39m\u001b[34m(self, thread_id, user_message, stream_callback, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m         response += chunk\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     agent_response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthread_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m     response = agent_prefix + agent_response\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Store agent response in memory if possible\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/moya/agents/openai_agent.py:91\u001b[39m, in \u001b[36mOpenAIAgent.handle_message\u001b[39m\u001b[34m(self, message, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhandle_message\u001b[39m(\u001b[38;5;28mself\u001b[39m, message: \u001b[38;5;28mstr\u001b[39m, **kwargs) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     88\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03m    Calls OpenAI ChatCompletion to handle the user's message.\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/moya/agents/openai_agent.py:116\u001b[39m, in \u001b[36mOpenAIAgent.handle\u001b[39m\u001b[34m(self, user_message)\u001b[39m\n\u001b[32m    113\u001b[39m iteration = \u001b[32m0\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m iteration < \u001b[38;5;28mself\u001b[39m.max_iterations:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     message = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m# Extract message content\u001b[39;00m\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/moya/agents/openai_agent.py:209\u001b[39m, in \u001b[36mOpenAIAgent.get_response\u001b[39m\u001b[34m(self, conversation)\u001b[39m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_tool_definitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtool_registry\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m     message = response.choices[\u001b[32m0\u001b[39m].message\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# Convert the response to a dict for uniform handling\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:914\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    873\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    911\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    912\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    913\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/openai/_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/openai/_base_client.py:919\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    917\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/openai/_base_client.py:955\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m    952\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, request.method, request.url)\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    961\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpx/_client.py:926\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    924\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    933\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpx/_client.py:954\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    951\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m954\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    959\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    960\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpx/_client.py:991\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    989\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    993\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpx/_client.py:1027\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1023\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1024\u001b[39m     )\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1027\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1031\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:236\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    223\u001b[39m req = httpcore.Request(\n\u001b[32m    224\u001b[39m     method=request.method,\n\u001b[32m    225\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     extensions=request.extensions,\n\u001b[32m    234\u001b[39m )\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    241\u001b[39m     status_code=resp.status,\n\u001b[32m    242\u001b[39m     headers=resp.headers,\n\u001b[32m    243\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    244\u001b[39m     extensions=resp.extensions,\n\u001b[32m    245\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/HackIIIT/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/ssl.py:1232\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1230\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1231\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Create a new thread for this collaborative session\n",
    "collab_thread_id = \"comedy_collab_001\"\n",
    "\n",
    "# Start with a comedy challenge that requires collaborative effort\n",
    "initial_challenge = \"\"\"Create a comedy sketch that combines physical comedy with social commentary \n",
    "about social media influence. It should be appropriate for a live theater audience.\"\"\"\n",
    "\n",
    "# Store the challenge in memory\n",
    "EphemeralMemory.store_message(thread_id=collab_thread_id, sender=\"user\", content=initial_challenge)\n",
    "print(\"Stored initial challenge in memory\\n\")\n",
    "\n",
    "# First, let the concept generator propose ideas\n",
    "print(\"Collaborative Session - Concept Generator's Turn\\n\")\n",
    "concept_thoughts = orchestrator.orchestrate(\n",
    "    thread_id=collab_thread_id,\n",
    "    user_message=initial_challenge,\n",
    "    agent_name=\"concept_generator\"\n",
    ")\n",
    "EphemeralMemory.store_message(thread_id=collab_thread_id, sender=\"concept_generator\", content=concept_thoughts)\n",
    "print(f\"Concept Generator: {concept_thoughts}\\n\")\n",
    "\n",
    "# Dialogue refiner builds on concept generator's input\n",
    "dialogue_prompt = \"Based on the concept generator's ideas, create compelling dialogue for this sketch about social media influence.\"\n",
    "print(\"Collaborative Session - Dialogue Refiner's Turn\\n\")\n",
    "\n",
    "# Get conversation summary from memory\n",
    "summary_tool = tool_registry.get_tool(\"get_summary\")\n",
    "if summary_tool:\n",
    "    summary = summary_tool.function(thread_id=collab_thread_id)\n",
    "\n",
    "dialogue_contribution = orchestrator.orchestrate(\n",
    "    thread_id=collab_thread_id,\n",
    "    user_message=dialogue_prompt + \"\\n\\nPrevious contributions: \" + summary,\n",
    "    agent_name=\"dialogue_refiner\"\n",
    ")\n",
    "EphemeralMemory.store_message(thread_id=collab_thread_id, sender=\"dialogue_refiner\", content=dialogue_contribution)\n",
    "print(f\"Dialogue Refiner: {dialogue_contribution}\\n\")\n",
    "\n",
    "# Structure agent organizes everything\n",
    "structure_prompt = \"Based on the concept and dialogue provided, create a structured outline for this social media sketch.\"\n",
    "\n",
    "print(\"Collaborative Session - Structure & Timing Agent's Turn\\n\")\n",
    "\n",
    "# Get updated conversation summary\n",
    "if summary_tool:\n",
    "    summary = summary_tool.function(thread_id=collab_thread_id)\n",
    "\n",
    "structure_contribution = orchestrator.orchestrate(\n",
    "    thread_id=collab_thread_id,\n",
    "    user_message=structure_prompt + \"\\n\\nPrevious contributions: \" + summary,\n",
    "    agent_name=\"structure_timing\"\n",
    ")\n",
    "EphemeralMemory.store_message(thread_id=collab_thread_id, sender=\"structure_timing\", content=structure_contribution)\n",
    "print(f\"Structure & Timing Agent: {structure_contribution}\\n\")\n",
    "\n",
    "# Audience adaptation agent tailors it for live theater\n",
    "adaptation_prompt = \"Tailor this sketch specifically for a live theater audience, highlighting elements that would work well in that medium.\"\n",
    "\n",
    "print(\"Collaborative Session - Audience Adaptation Agent's Turn\\n\")\n",
    "\n",
    "# Get updated conversation summary\n",
    "if summary_tool:\n",
    "    summary = summary_tool.function(thread_id=collab_thread_id)\n",
    "\n",
    "adaptation_contribution = orchestrator.orchestrate(\n",
    "    thread_id=collab_thread_id,\n",
    "    user_message=adaptation_prompt + \"\\n\\nPrevious contributions: \" + summary,\n",
    "    agent_name=\"audience_adaptation\"\n",
    ")\n",
    "EphemeralMemory.store_message(thread_id=collab_thread_id, sender=\"audience_adaptation\", content=adaptation_contribution)\n",
    "print(f\"Audience Adaptation Agent: {adaptation_contribution}\\n\")\n",
    "\n",
    "# Final touches from variation agent\n",
    "variation_prompt = \"Suggest some unexpected twists or alternative approaches to make this social media sketch truly original.\"\n",
    "\n",
    "print(\"Collaborative Session - Variation Agent's Turn\\n\")\n",
    "\n",
    "# Get final conversation summary\n",
    "if summary_tool:\n",
    "    summary = summary_tool.function(thread_id=collab_thread_id)\n",
    "\n",
    "variation_contribution = orchestrator.orchestrate(\n",
    "    thread_id=collab_thread_id,\n",
    "    user_message=variation_prompt + \"\\n\\nPrevious contributions: \" + summary,\n",
    "    agent_name=\"variation_agent\"\n",
    ")\n",
    "EphemeralMemory.store_message(thread_id=collab_thread_id, sender=\"variation_agent\", content=variation_contribution)\n",
    "print(f\"Variation Agent: {variation_contribution}\\n\")\n",
    "\n",
    "# Get the complete collaborative sketch\n",
    "print(\"Complete Collaborative Comedy Sketch:\\n\")\n",
    "if summary_tool:\n",
    "    final_sketch = summary_tool.function(thread_id=collab_thread_id)\n",
    "    print(final_sketch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Multi-Agent Interaction\n",
    "\n",
    "Now let's demonstrate dynamic agent selection using the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a message that doesn't explicitly specify which agent should handle it\n",
    "ambiguous_query = \"\"\"I need help creating a sketch about awkward family gatherings during \n",
    "holidays that would work well in a short-form video format. What would be a good approach?\"\"\"\n",
    "\n",
    "# Create a new thread ID for this query\n",
    "ambiguous_thread_id = \"sketch_ambiguous_001\"\n",
    "\n",
    "# Let the orchestrator determine which agent should handle this query\n",
    "print(\"Demonstrating dynamic agent selection with classifier...\\n\")\n",
    "response = orchestrator.orchestrate(\n",
    "    thread_id=ambiguous_thread_id,\n",
    "    user_message=ambiguous_query\n",
    "    # Note: we're not specifying an agent_name, so the classifier will choose\n",
    ")\n",
    "\n",
    "print(f\"Response from the most appropriate agent:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes user input for a comedy sketch and stores the final script\n",
    "\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "\n",
    "# Create output and logs directories if they don't exist\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "def create_sketch(topic, audience=\"YouTube\", format_type=\"video\"):\n",
    "    \"\"\"\n",
    "    Create a comedy sketch using the multi-agent system\n",
    "    \n",
    "    Parameters:\n",
    "    topic (str): The main topic or theme for the comedy sketch\n",
    "    audience (str): Target audience platform (e.g., YouTube, TikTok, live theater)\n",
    "    format_type (str): Format of the sketch (e.g., video, audio, text)\n",
    "    \n",
    "    Returns:\n",
    "    str: The final comedy sketch script\n",
    "    \"\"\"\n",
    "    # Create a new thread ID for this request\n",
    "    thread_id = f\"sketch_request_{topic.replace(' ', '_').lower()}\"\n",
    "    \n",
    "    # Initialize logging\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    log_file_path = f\"logs/{topic.replace(' ', '_').lower()}_{timestamp}_log.md\"\n",
    "    \n",
    "    def log_to_file(step, message_type, content):\n",
    "        \"\"\"Helper function to log to the file\"\"\"\n",
    "        with open(log_file_path, \"a\") as log_file:\n",
    "            log_file.write(f\"## {step}: {message_type}\\n\\n\")\n",
    "            log_file.write(f\"{content}\\n\\n\")\n",
    "            log_file.write(\"---\\n\\n\")\n",
    "    \n",
    "    # Start logging with header\n",
    "    with open(log_file_path, \"w\") as log_file:\n",
    "        log_file.write(f\"# Comedy Sketch Creation Log: {topic}\\n\\n\")\n",
    "        log_file.write(f\"- **Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        log_file.write(f\"- **Topic:** {topic}\\n\")\n",
    "        log_file.write(f\"- **Audience:** {audience}\\n\")\n",
    "        log_file.write(f\"- **Format:** {format_type}\\n\\n\")\n",
    "        log_file.write(\"---\\n\\n\")\n",
    "    \n",
    "    # Format the user request\n",
    "    user_request = f\"I need a comedy sketch about {topic}, suitable for a {audience} audience in {format_type} format.\"\n",
    "    \n",
    "    # Log the initial request\n",
    "    log_to_file(\"Initial Request\", \"User Input\", user_request)\n",
    "    \n",
    "    # Store user request in memory\n",
    "    EphemeralMemory.store_message(thread_id=thread_id, sender=\"user\", content=user_request)\n",
    "    print(f\"Creating a comedy sketch about {topic} for {audience}...\\n\")\n",
    "    \n",
    "    # Step 1: Concept Generation\n",
    "    concept_task = f\"\"\"Generate 3 unique comedy sketch concepts about {topic}. \n",
    "    Each concept should include a brief premise, key characters, and the central comedic tension. \n",
    "    Make the concepts fresh, engaging, and suitable for a {audience} audience.\"\"\"\n",
    "    \n",
    "    # Log the concept generation prompt\n",
    "    log_to_file(\"Step 1\", \"Prompt to Concept Generator\", concept_task)\n",
    "    \n",
    "    print(\"Step 1: Generating concepts...\")\n",
    "    concept_response = orchestrator.orchestrate(\n",
    "        thread_id=thread_id,\n",
    "        user_message=concept_task,\n",
    "        agent_name=\"concept_generator\"\n",
    "    )\n",
    "    \n",
    "    # Log the concept generator's response\n",
    "    log_to_file(\"Step 1\", \"Response from Concept Generator\", concept_response)\n",
    "    \n",
    "    # Step 2: Dialogue Development\n",
    "    dialogue_task = f\"\"\"Based on the concepts provided, choose the most promising one and develop \n",
    "    engaging dialogue for it. Create witty one-liners, comedic callbacks, and ensure proper \n",
    "    setup and delivery. Focus on making the dialogue sound natural while maximizing humor.\"\"\"\n",
    "    \n",
    "    print(\"Step 2: Developing dialogue...\")\n",
    "    summary = summary_tool.function(thread_id=thread_id) if summary_tool else \"\"\n",
    "    \n",
    "    # Log the dialogue development prompt with summary\n",
    "    full_dialogue_prompt = dialogue_task + \"\\n\\nRefer to the previous concepts: \" + summary\n",
    "    log_to_file(\"Step 2\", \"Prompt to Dialogue Refiner\", full_dialogue_prompt)\n",
    "    \n",
    "    dialogue_response = orchestrator.orchestrate(\n",
    "        thread_id=thread_id,\n",
    "        user_message=full_dialogue_prompt,\n",
    "        agent_name=\"dialogue_refiner\"\n",
    "    )\n",
    "    \n",
    "    # Log the dialogue refiner's response\n",
    "    log_to_file(\"Step 2\", \"Response from Dialogue Refiner\", dialogue_response)\n",
    "    \n",
    "    # Step 3: Structure & Timing\n",
    "    structure_task = f\"\"\"Based on the concept and dialogue developed so far, create a structured \n",
    "    sketch outline with proper comedic escalation, beats, and timing cues. Ensure the sketch \n",
    "    flows naturally, building to a satisfying comedic climax. Include specific guidance on \n",
    "    how to pace the performance for maximum comedic impact.\"\"\"\n",
    "    \n",
    "    print(\"Step 3: Creating structure and timing...\")\n",
    "    summary = summary_tool.function(thread_id=thread_id) if summary_tool else \"\"\n",
    "    \n",
    "    # Log the structure prompt with summary\n",
    "    full_structure_prompt = structure_task + \"\\n\\nRefer to the previous work: \" + summary\n",
    "    log_to_file(\"Step 3\", \"Prompt to Structure & Timing Agent\", full_structure_prompt)\n",
    "    \n",
    "    structure_response = orchestrator.orchestrate(\n",
    "        thread_id=thread_id,\n",
    "        user_message=full_structure_prompt,\n",
    "        agent_name=\"structure_timing\"\n",
    "    )\n",
    "    \n",
    "    # Log the structure response\n",
    "    log_to_file(\"Step 3\", \"Response from Structure & Timing Agent\", structure_response)\n",
    "    \n",
    "    # Step 4: Audience Adaptation\n",
    "    adaptation_task = f\"\"\"Adapt the sketch to ensure it resonates specifically with a {audience} \n",
    "    audience. Adjust tone, references, and comedic elements to maximize appeal \n",
    "    and relatability for this audience. Suggest any platform-specific considerations \n",
    "    that would enhance the sketch's success.\"\"\"\n",
    "    \n",
    "    print(\"Step 4: Adapting for audience...\")\n",
    "    summary = summary_tool.function(thread_id=thread_id) if summary_tool else \"\"\n",
    "    \n",
    "    # Log the adaptation prompt with summary\n",
    "    full_adaptation_prompt = adaptation_task + \"\\n\\nRefer to the previous work: \" + summary\n",
    "    log_to_file(\"Step 4\", \"Prompt to Audience Adaptation Agent\", full_adaptation_prompt)\n",
    "    \n",
    "    adaptation_response = orchestrator.orchestrate(\n",
    "        thread_id=thread_id,\n",
    "        user_message=full_adaptation_prompt,\n",
    "        agent_name=\"audience_adaptation\"\n",
    "    )\n",
    "    \n",
    "    # Log the adaptation response\n",
    "    log_to_file(\"Step 4\", \"Response from Audience Adaptation Agent\", adaptation_response)\n",
    "    \n",
    "    # Step 5: Creative Variations\n",
    "    variation_task = \"\"\"Based on the sketch developed so far, provide 2-3 creative variations or \n",
    "    unexpected twists that could make the comedy more unique and less predictable. Suggest \n",
    "    alternative endings, subversions of expected tropes, or surprising character choices \n",
    "    that maintain the core concept while adding originality.\"\"\"\n",
    "    \n",
    "    print(\"Step 5: Adding creative variations...\")\n",
    "    summary = summary_tool.function(thread_id=thread_id) if summary_tool else \"\"\n",
    "    \n",
    "    # Log the variation prompt with summary\n",
    "    full_variation_prompt = variation_task + \"\\n\\nRefer to the previous work: \" + summary\n",
    "    log_to_file(\"Step 5\", \"Prompt to Variation Agent\", full_variation_prompt)\n",
    "    \n",
    "    variation_response = orchestrator.orchestrate(\n",
    "        thread_id=thread_id,\n",
    "        user_message=full_variation_prompt,\n",
    "        agent_name=\"variation_agent\"\n",
    "    )\n",
    "    \n",
    "    # Log the variation response\n",
    "    log_to_file(\"Step 5\", \"Response from Variation Agent\", variation_response)\n",
    "    \n",
    "    # Get the complete sketch history\n",
    "    complete_sketch = summary_tool.function(thread_id=thread_id) if summary_tool else \"\"\n",
    "    \n",
    "    # Extract the final script by isolating the dialogue part\n",
    "    # This is a simplified extraction - in practice you might want more complex parsing\n",
    "    final_script = dialogue_response\n",
    "    \n",
    "    # Format the final script with any adaptations and selected variations\n",
    "    sketch_title = f\"Comedy Sketch: {topic.title()}\"\n",
    "    formatted_script = f\"\"\"# {sketch_title}\n",
    "\n",
    "## Overview\n",
    "A comedy sketch about {topic} created for {audience}.\n",
    "\n",
    "## Script\n",
    "{final_script}\n",
    "\n",
    "## Production Notes\n",
    "### Structure & Timing\n",
    "{structure_response}\n",
    "\n",
    "### Audience Adaptation\n",
    "{adaptation_response}\n",
    "\n",
    "### Possible Variations\n",
    "{variation_response}\n",
    "\"\"\"\n",
    "    \n",
    "    # Save the script to a file\n",
    "    filename = f\"output/{topic.replace(' ', '_').lower()}_sketch.md\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(formatted_script)\n",
    "    \n",
    "    # Log the final output\n",
    "    log_to_file(\"Final Output\", \"Complete Comedy Sketch\", formatted_script)\n",
    "    \n",
    "    print(f\"\\nSketch completed! Saved to {filename}\")\n",
    "    print(f\"Complete log saved to {log_file_path}\")\n",
    "    \n",
    "    # Display a preview\n",
    "    display(Markdown(f\"## Preview of '{sketch_title}'\\n\\n```\\n{final_script[:500]}...\\n```\\n\\n[Full script saved to {filename}]\\n[Complete log saved to {log_file_path}]\"))\n",
    "    \n",
    "    return final_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a comedy sketch about Indian Wedding for YouTube...\n",
      "\n",
      "Step 1: Generating concepts...\n",
      "Step 2: Developing dialogue...\n",
      "Step 3: Creating structure and timing...\n",
      "Step 4: Adapting for audience...\n",
      "Step 5: Adding creative variations...\n",
      "\n",
      "Sketch completed! Saved to output/indian_wedding_sketch.md\n",
      "Complete log saved to logs/indian_wedding_2025-03-16_12-25-04_log.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Preview of 'Comedy Sketch: Indian Wedding'\n",
       "\n",
       "```\n",
       "[dialogue_refiner] The dialogue for \"The Overzealous Wedding Planner\" has been developed and stored successfully! Here it is for your reference:\n",
       "\n",
       "### The Overzealous Wedding Planner\n",
       "\n",
       "**Characters:**\n",
       "- Pinky the Wedding Planner\n",
       "- Mr. Sharma\n",
       "- Mrs. Sharma\n",
       "- Sia Sharma\n",
       "- Rohan Verma\n",
       "\n",
       "**Setup:**\n",
       "The sketch opens with Pinky excitedly showing Mr. and Mrs. Sharma and Sia a vision board filled with extravagant ideas for the wedding. Sia looks overwhelmed while her parents seem skeptical.\n",
       "\n",
       "**Scene 1:**\n",
       "\n",
       "...\n",
       "```\n",
       "\n",
       "[Full script saved to output/indian_wedding_sketch.md]\n",
       "[Complete log saved to logs/indian_wedding_2025-03-16_12-25-04_log.md]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to create your custom comedy sketch!\n",
    "\n",
    "# Replace these values with your desired parameters\n",
    "topic = \"Indian Wedding\"  # The main topic/theme for the comedy sketch\n",
    "audience = \"YouTube\"  # Target platform (YouTube, TikTok, Netflix, live theater, etc.)\n",
    "format_type = \"2 minute video\"  # Format (video, audio, live performance, etc.)\n",
    "\n",
    "# Create the sketch\n",
    "final_script = create_sketch(\n",
    "    topic=topic,\n",
    "    audience=audience, \n",
    "    format_type=format_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
